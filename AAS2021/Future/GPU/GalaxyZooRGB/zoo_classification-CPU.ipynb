{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Zoo Classification GPU Demo\n",
    "\n",
    "Using votes from the Galaxy Zoo project as target indicators, we create a convolutional neural network (CNN) predictor for galaxy types based on small image cutouts from SDSS centered on the galaxy. To keep things simple, while still producing a reasonable predictor, we have limited the target to select a class in **EL** (elliptical), **CS** (spiral, of any type), and **DK** (unkown/ambiguous). The labels for training were chosen from \"high-confidence\" votes, where either > 75% of votes were for either of **EL** or **CS**, or neither of those had > 25% of votes, in which case we assign **DK**. We created a dataset of 10,000 objects from the `DR10.zooVotes` table in casjobs, and obtained jpeg image cutouts from SkyServer at 0.2' per pixel resolution and a size of 128 x 128 pixels centered on each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "The target labels have been prepared in **t_el**, **t_cs**, and **t_dk** with a flag of 1 for member and 0 for non-member, which can be used directly in the model training. The images have been combined together in an array indexed in the same way as the table containing the target labels and packaged in a file suitable for reading directy into a numpy array (size 10000 samples x 128 pixels x 128 pixels x 3 color channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_votes = pd.read_csv('zoo_votes.csv', index_col=0)\n",
    "images = np.load('zoo_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr7objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>p_el</th>\n",
       "      <th>p_cs</th>\n",
       "      <th>t_el</th>\n",
       "      <th>t_cs</th>\n",
       "      <th>t_dk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587722952230175035</td>\n",
       "      <td>236.2869</td>\n",
       "      <td>-0.518000</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587722952230175138</td>\n",
       "      <td>236.3422</td>\n",
       "      <td>-0.467028</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587722952230175173</td>\n",
       "      <td>236.3693</td>\n",
       "      <td>-0.574445</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587722952230240617</td>\n",
       "      <td>236.3973</td>\n",
       "      <td>-0.493472</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587722952230306133</td>\n",
       "      <td>236.5877</td>\n",
       "      <td>-0.554444</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr7objid        ra       dec   p_el   p_cs  t_el  t_cs  t_dk\n",
       "0  587722952230175035  236.2869 -0.518000  0.152  0.818     0     1     0\n",
       "1  587722952230175138  236.3422 -0.467028  0.211  0.763     0     1     0\n",
       "2  587722952230175173  236.3693 -0.574445  0.077  0.923     0     1     0\n",
       "3  587722952230240617  236.3973 -0.493472  0.000  1.000     0     1     0\n",
       "4  587722952230306133  236.5877 -0.554444  0.147  0.853     0     1     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo_votes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare target labels\n",
    "\n",
    "For training the model, prepare an array of n_samples x n_classes. Here we see the breakdown of number of samples per class in the dataset (which resemble that in the larget galaxy zoo dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_labs = ['t_el', 't_cs', 't_dk']\n",
    "targets = zoo_votes[targ_labs].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(targ_labs, targets.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to convince ourselves that each object is only assigned to one category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.sum() == len(zoo_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "We use tensorflow/keras to build a model based on an existing pretrained image classification network, and add layers to make compatible with the 3 class problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = tf.keras.applications.resnet.ResNet101(input_shape=(128, 128, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(res)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(targets.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Here we show the devices available to tensorflow for training. On a GPU system, this will have devices tagged \"GPU\" in addition to the CPU devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set aside a validation dataset to be used to evaluate performance of the model and show classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, Y_tr, Y_te = train_test_split(images, targets, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_in = tf.keras.applications.resnet.preprocess_input(np.copy(X_tr))\n",
    "X_te_in = tf.keras.applications.resnet.preprocess_input(np.copy(X_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.7940 "
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "model.fit(X_tr_in, Y_tr, epochs=4, validation_data=(X_te_in, Y_te))\n",
    "print(f'Total wall time: {time.time() - tstart:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate classification performance\n",
    "\n",
    "using the test set we created earlier, make predictions and then plot the ROC curve showing the false positive and true positive rates as a function of classification threshold (e.g. label class X if P_x > threshold), for each of the classes separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_te = model.predict(X_te_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, 1, figsize = (12,7))\n",
    "for i in range(targets.shape[1]):\n",
    "    fpr, tpr, thresholds = roc_curve(Y_te[:, i], pred_te[:, i])\n",
    "    auc_ = auc(fpr, tpr)\n",
    "    plt.step(fpr, tpr, label=f'{targ_labs[i]} - AUC: {auc_:0.2f}')\n",
    "plt.plot([0,1], [0,1], ls='--', c='k')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `argmax` to identify the most-likely class, assign labels to the test data. The distribution of classes predicted in the test set looks similar to the overall dataset, with a bit larger share of spiral galaxies, but the trend largely holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_argmax_lab = label_binarize(pred_te.argmax(axis=1), classes=range(len(targ_labs)))\n",
    "plt.bar(targ_labs, pred_argmax_lab.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the results\n",
    "\n",
    "Finally, display some images predictions in each of the 3 classes. These predictions all look pretty good to the human eye, and it is fairly clear what constitutes unkown or ambiguous objects! A pretty good result for about 5 minutes of training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_el = np.where(pred_argmax_lab[:, 0])[0]\n",
    "cand_cs = np.where(pred_argmax_lab[:, 1])[0]\n",
    "cand_dk = np.where(pred_argmax_lab[:, 2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(3, 5, figsize=[16, 8])\n",
    "f.suptitle('predicted class associations')\n",
    "for i in range(a.shape[1]):\n",
    "    plt.sca(a[0][i])\n",
    "    plt.imshow(X_te[cand_el[i]])\n",
    "    i == 0 and plt.ylabel('eliptical')\n",
    "for i in range(a.shape[1]):\n",
    "    plt.sca(a[1][i])\n",
    "    plt.imshow(X_te[cand_cs[i]])\n",
    "    i == 0 and plt.ylabel('spiral')\n",
    "for i in range(a.shape[1]):\n",
    "    plt.sca(a[2][i])\n",
    "    plt.imshow(X_te[cand_dk[i]])\n",
    "    i == 0 and plt.ylabel('ambiguous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "sciserver": {
   "copySource": {
    "path": "GalZooClassDemo/fetch_data",
    "volId": "49850",
    "volType": "uservolumes"
   },
   "imageInfo": {
    "cachedContainer": {
     "arik": 68570
    },
    "dataVolumes": [],
    "domain": 16,
    "name": "GPU Essentials",
    "userVolumes": [
     66068,
     49850,
     49851
    ]
   },
   "lastEdit": {
    "time": 1610041601557,
    "user": "arik"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
